# -*- coding: utf-8 -*-
"""AI_HW1_Regression_with_inference_pro_pt1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HNLiOyslpYjQz4AAGMQiRPL2V8ub9yzc

<a href="https://colab.research.google.com/github/Murcha1990/ML_AI25/blob/main/Hometasks/Pro/AI_HW1_Regression_with_inference_pro_pt1.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

# **Домашнее задание №1 (pro). Часть 1**

В этом домашнем задании (его первой части) вам будет необходимо:
*  обучить модель регрессии для предсказания стоимости автомобилей;


> Оценка за первую часть домашки = $min(\text{ваш балл}, 7)$

**Примечание**

В каждой части оцениваются как код, **так и ответы на вопросы.** Вопросы подсвечены синим цветом.

Если нет одного и/или другого, то часть баллов за соответствующее задание снимается.
"""

!pip install phik

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import random
import seaborn as sns
import itertools

from sklearn.base import BaseEstimator, RegressorMixin
from sklearn.linear_model import LinearRegression, ElasticNet
from sklearn.utils.validation import check_X_y, check_array, check_is_fitted
from sklearn.model_selection import GridSearchCV
from phik import phik_matrix

random.seed(42)
np.random.seed(42)

"""### **Задание 0**
Давайте зафиксируем важный момент.

**Задание 0 (0 баллов).**
Изучите и ответье на вопрос: для чего фиксируем сиды в домашках?

> Чтобы результат, полученный в домашке, можно было воспроизвести (по сиду генерируется последовательность псевдослучайных чисел)

# **Часть 1 | EDA**


Первая часть состоит из классических шагов EDA:

- Базовый EDA и обработка признаков (1.7 балла)
- Визуализации признаков и их анализ (1.6 балл)

Всего можно набрать 3.3 основных балла и 0.25 бонусных.

В следующих частях, вы увидите бонусные задания. Бонусные задания выделены как **Дополнительное задание/Бонус**. Вы можете выполнять их, чтобы в случае ошибок в основных задачах всё равно набрать за работу максимум. Кроме того, дополнительные задания позволяют вам углубить знания.

Призываем активно использовать их!

## **Простейший EDA и обработка признаков (1.7 балла)**
"""

df_train = pd.read_csv('https://raw.githubusercontent.com/Murcha1990/MLDS_ML_2022/main/Hometasks/HT1/cars_train.csv')
df_test = pd.read_csv('https://raw.githubusercontent.com/Murcha1990/MLDS_ML_2022/main/Hometasks/HT1/cars_test.csv')

print("Train data shape:", df_train.shape)
print("Test data shape: ", df_test.shape)

"""### **Задание 1.(0.4 балла)**
Выполните операции, направленные на базовое исследование данных:

- [ ] Посмотрите, есть ли в датасете пропуски и дубликаты. Запишите/выведите названия колонок, для которых есть пропущенные значения (0.1 балла)
- [ ] Посмотрите, есть ли в данных явные дубликаты (0.05 балла)
- [ ] Постройте дашборд в одну строку, используя [ydata-profilling](https://github.com/ydataai/ydata-profiling)(0.15 балла)
- [ ] Опишите базовые выводы (какие — выберите сами), используя дашборд (0.2 балла).
"""

df_train.info()

"""> Пропуски есть в mileage, engine, max_power, torque, seats"""

df_train.duplicated().sum()

for i in range(0, len(df_train)):
  try:
    ffil_value = float(df_train.loc[i, 'max_power'][:-4])
    df_train.loc[i, 'max_power'] = ffil_value

  except:
    if df_train.loc[i, 'max_power'] in [np.nan, 'nan']:
      continue
    elif df_train.loc[i, 'max_power'] == '0':
      ffil_value = float(df_train.loc[i, 'max_power'])
      df_train.loc[i, 'max_power'] = ffil_value
    else:
      df_train.loc[i, 'max_power'] = 0

# !pip install ydata-profiling

# from ydata_profiling import ProfileReport

# profile = ProfileReport(df_train, title="Профайлинг")
# html = profile.to_html()

# with open('report.html', 'w') as file:
#   file.write(html)

# # profile.to_notebook_iframe()

"""> ### Выводы по дата-профайлингу:

- Есть 493 дубликата (около 7% всех строк), их нужно убрать
- Профайлер заметил высокую корреляцию между рядом признаков, надо будет что-то с этим сделать
- Большинство колонок текстовые / категориальные, нужно будет их перекодировать
- mileage представлен как текст, но по факту это числовой признак. Нужно будет его перевести в численный вид. Аналогично с torque.
- Признак engine имеет 120 уникальных значений, с ним нужно будет что-то придумать (вероятно цифры до "СС" имеют какой-то числовой смысл)
- Признак seller_type несбалансированный, стоит это учесть при работе с ним
- Признак max_power числовой, но представлен не в числовом виде

### **Задание 2 (0.2 балла)**
Проанализируйте статистики датасета.

**Ваша задача:**
- [ ] Посчитайте основные статистики по числовым столбцам для трейна и теста
- [ ] Посчитайте основные статистики по категориальным столбцам для трейна и теста
- [ ] Сравните среднее и медиану внутри `train`, внутри `test` и между собой. О чём могут говорить результаты?
- [ ] Сделайте выводы по статистикам. Отсутсвие выводов равносильно по баллам невыполнению задания.

**Подсказка:**

Используте ``.describe()`` с нужным(и) аргументом(-ами).
"""

df_train.describe()

df_test.describe()

df_train.describe(include=['object'])

df_test.describe(include=['object'])

num_cols_train = df_train.select_dtypes(include=['number']).columns
num_cols_test = df_test.select_dtypes(include=['number']).columns

compare = pd.DataFrame({
    'train_mean': df_train.describe().loc['mean'],
    'test_mean': df_test.describe().loc['mean'],
    'train_median': df_train[num_cols_train].median(),
    'test_median': df_test[num_cols_test].median()
})
compare

"""> Среднее и медиана на трейне и тесте отличаются незначительно (2-3%) - свидетельствует о том, что выборки сделаны случайным и независим способом

### Выводы

- mileage, engine, torque, max_power необходимо аккуратно перевести в численный формат (слишком много уникальных значений)
- name также имеет очень много значений, с ним нужно будет что-то придумать
- остальные категориальные признаки легко можно будет перекодировать, тк уникальных значений немного
- основные статистики на трейне и тесте мало отличаются, разбиение можно считать случайным и независимым
- нет ни одной машины менее, чем с двумя сиденьями :)

### **Задание 3 (0.2 балла)**

- [ ] Посмотрите, есть ли в трейне объекты с одинаковым признаковым описанием (целевую переменную следует исключить). Если есть, то сколько? (0.01 балла)
- [ ] Отобразите такие объекты (0.01 балла)
- [ ] Удалите повторяющиеся строки. Если при одинаковом признаковом описании цены на автомобили отличаются, то оставьте первую строку по этому автомобилю (0.01 балла)
- [ ]  Обновите индексы строк таким образом, чтобы они шли от 0 без пропусков (0.01 балла)
- [ ] Подумайте, могут ли в данных быть другие скрытые дубли? Предложите, как их можно отлавливать. (0.16 балла)

P.S тут данные без подвоха, но выводы нам нужны.
"""

features = df_train.drop(columns='selling_price', axis=1).columns
df_train[features].duplicated().sum()

"""> Есть 1159 дублирующихся строки"""

df_train[df_train[features].duplicated()]

df_train = df = df_train.drop_duplicates(subset=features, keep='first')
df_train = df.reset_index(drop=True)
df_train

assert df_train.shape == (5840, 13)

"""### Скрытые дубли
> Также можно привести к нижнему регистру и убрать пробелы в столбце name
"""

df_train['name_normalized'] = df_train['name'].str.lower().str.strip()

df_train['name'].nunique()

df_train['name_normalized'].nunique()

features = df_train.drop(columns=['selling_price', 'name'], axis=1).columns
df_train[features].duplicated().sum()

df_train = df_train.drop(columns='name_normalized', axis=1)

"""> Новых дублей не нашли :(

> Также в теории можно поискать почти полные дубли (где в одном из вариантов пропущено 1-2 признака, поэтому он не ловится через .duplicated())

> Или обратить внимание на столбец torque, который записан странным образом.

### **Задание 4 (0.3 балла)**

Вы могли заметить, что с признаками ``mileage, engine, max_power и torque`` всё не очень хорошо. Они распознаются как строки (можно убедиться в этом, вызвав `data.dtypes`). Однако эти переменные не являются категориальными — они — числа. Соответственно, нужно привести их к числовому виду.

**Задача :**
* [ ] Уберите единицы измерения для признаков ``mileage, engine, max_power``.
* [ ] Приведите тип данных к ``float``.
* [ ] Предобработайте признак `torque` — разделите его на два: собственно `torque` и `max_torque_rpm`. Учтите единицы измерения


**Важно**
- Все действия нужно производить над обоими датасетами — `train` и `test`.
"""

strange_features = ['mileage', 'engine', 'max_power', 'torque']
df_train[strange_features]

"""> Пофиксим mileage"""

df_train['mileage'] = df_train['mileage'].apply(lambda x: x.split()[0] if pd.notna(x) else None)
df_train['mileage'] = df_train['mileage'].astype(float)
df_train['mileage'].head()

df_test['mileage'] = df_test['mileage'].apply(lambda x: x.split()[0] if pd.notna(x) else None)
df_test['mileage'] = df_test['mileage'].astype(float)
df_test['mileage'].head()

"""> Пофиксим engine"""

df_train['engine'] = df_train['engine'].apply(lambda x: x.split()[0] if pd.notna(x) else None)
df_train['engine'] = df_train['engine'].astype(float)
df_train['engine'].head()

df_test['engine'] = df_test['engine'].apply(lambda x: x.split()[0] if pd.notna(x) else None)
df_test['engine'] = df_test['engine'].astype(float)
df_test['engine'].head()

"""> Пофиксим max_power"""

df_train['max_power'] = df_train['max_power'].astype(float)
df_train['max_power'].head()

df_test['max_power'] = df_test['max_power'].apply(lambda x: x.split()[0] if pd.notna(x) else None)
df_test['max_power'] = df_test['max_power'].astype(float)
df_test['max_power'].head()

"""> Пофиксим torque

> Принцип работы функции: Функция извлекает из текстовой строки два числовых значения: крутящий момент (в Nm или kgm, конвертируя kgm в Nm умножением на 9.80665) и обороты двигателя (rpm, усредняя если указан диапазон)
"""

import re

def parse_torque(torque_str): # код написан с помощью Claude-Sonnet
    """
    Парсит строку torque и возвращает значение крутящего момента и обороты
    """
    if pd.isna(torque_str) or torque_str == '':
        return None, None

    torque_str = torque_str.lower()

    torque_value = None
    torque_match = re.search(r'([\d.]+)\s*(?:nm|kgm)', torque_str)
    if torque_match:
        torque_value = float(torque_match.group(1))
        if 'kgm' in torque_str:
            torque_value = torque_value * 9.80665

    rpm_value = None
    rpm_match = re.search(r'[@at\s]+([\d,]+)(?:[-~]+([\d,]+))?\s*(?:\(?\s*(?:rpm|kgm)?)?', torque_str)
    if rpm_match:
        rpm1 = float(rpm_match.group(1).replace(',', ''))
        if rpm_match.group(2):
            rpm2 = float(rpm_match.group(2).replace(',', ''))
            rpm_value = (rpm1 + rpm2) / 2
        else:
            rpm_value = rpm1

    return torque_value, rpm_value

df_train[['torque', 'max_torque_rpm']] = df_train['torque'].apply(
    lambda x: pd.Series(parse_torque(x))
)
df_train['torque'].head()

df_test[['torque', 'max_torque_rpm']] = df_test['torque'].apply(
    lambda x: pd.Series(parse_torque(x))
)
df_test['torque'].head()

df_train[strange_features].info()

"""> Страшные признаки перекодированы

### **Задание 5 (0.3 балла)**

На первом шаге мы обнаружили пропуски. Давайте избавимся от них.

**Задание:**
- [ ] Заполните пропуски в столбцах медианами. Убедитесь, что после заполнения пропусков не осталось.
- [ ] Почему стоит применять именно медиану. Могли ли мы применить среднее? Обоснуйте свое рассуждение.
- [ ] Как правильно считать медиану для заполнения? Выберите верное утверждение:
 - По тестовым свою, по тренировочным — свою
 - По тренировочным данным для `train` и `test` - **верное**

> Посмотрим еще раз, в каких столбцах есть пропуски
"""

df_train.info()

df_test.info()

features_to_fill = ['mileage', 'engine', 'max_power', 'torque',
                    'seats', 'max_torque_rpm']

"""> До заполнения пропусков:"""

df_train_old = df_train.copy()
df_train[features_to_fill].describe()

"""До заполнения пропусков:"""

df_test_old = df_test.copy()
df_test[features_to_fill].describe()

"""> Видим, что у torque, max_power и max_torque_rpm есть выбросы (max во много раз больше mean) - поэтому стоит использовать именно медиану, а не среднее для заполнения пропусков"""

medians = {}
for col in features_to_fill:
    medians[col] = df_train[col].median()

for col in features_to_fill:
    df_train[col] = df_train[col].fillna(medians[col])
    df_test[col] = df_test[col].fillna(medians[col])

"""После заполнения:"""

df_train[features_to_fill].describe()

"""После заполнения:"""

df_test[features_to_fill].describe()

"""> Описательные статистики практически не изменились

> Убедимся, что пропусков не осталось
"""

df_train.info()

df_test.info()

"""> Считать медиану правильно для train и test именно по трейну - иначе может случиться утечка данных в тест, что не очень хорошо

### **Задание 6 (0.2 балла)**

Теперь, когда не осталось пропусков, давайте преобразуем столбцы к более подходящим типам. А именно столбцы ``engnine`` и ``seats`` к приведем к `int`.

- [ ] Осуществите приведение столбцов к необходимому типу.
- [ ] Ответье на вопрос — почему (хоть мы этого и не делаем) ``seats``, возможно рассмотреть как категориальную переменную?
"""

df_train['seats'] = df_train['seats'].astype(int)
df_train['engine'] = df_train['engine'].astype(int)

df_train['seats'].value_counts()

"""> В теории seats можно рассматривать как категориальную переменную, тк там ограниченное кол-во значений, плюс его числовой смысл не такой явный

> Можно рассматривать автомобили с n сидениями как определенную категорию.

### **Задание 7 (0.1 балла)**

Снова вызовите метод describe и проанализируйте статистики.

**Ответье на вопрос:**
- [ ] Есть ли основания предполагать, что заполнение пропусков свдинуло наши распределения? Могло ли это вообще возникнуть?
"""

df_train.describe()

df_test.describe()

delta_train = df_train.describe() - df_train_old.describe()
delta_train

"""> Как можно заметить, статистики изменились очень слабо - нет оснований предполагать, что распределения заметно изменились. Разве что снизилась дисперсия, тк мы добавили "центральных" наблюдений.

> В теории это могло произойти - если бы пропусков было больше, мы бы снизили дисперсию еще сильнее и изменение распределений было бы заметно.

## **Визуализации и корреляция (1.6 балла + 0.25)**

Визуализация данных — важный шаг в работе. Визуализировать данные необходимо, например, чтобы:

- Оценить распределения признаков самих по себе (это может натоклнуть вас на мысли о модели, которую можно использовать)
- Сравнить распределения на `train` и `test` — чтобы проверить, насколько информация, на которой вы будете обучаться согласуется с той, на которой модель должна работать
- Оценить есть ли явная связь признаков с целевой переменной

**Важно:**

Если распределения на `train` и `test` не совпадают, это не значит, что нужно перемешивать данные! Более корректно актуализировать задачу и уточнить, а не устарели ли данные `train`. Также полезным может быть собрать новую тестовую выборку, смешав те, что имеются сейчас.

**Если вы будете подгонять распределения, то можете встретиться с переобучением!**

### **Задание 8 (0.5 балла)**

Шаг 1.
- [ ] Воспользуйтесь `pairplot` из библиотеки `seabron`, чтобы визуализировать попарные распределения числовых признаков для `train`
- [ ] По полученному графику ответьте на вопросы:
 - Можно ли предположить на основе распределений связь признаков с целевой переменной?
 - Можно ли предположить на основе распределений выдвинуть гипотезу о корреляциях признаков?

Шаг 2.

- [ ] Постройте pairplot по тестовым данным
- [ ] Ответьте на вопрос "Похожими ли оказались совокупности при разделении на трейн и тест?"
"""

df_train.info()

num_cols = df_train.select_dtypes(include=['int64', 'float64']).columns
num_cols

plt.figure(figsize=(12, 10))
sns.set_style("darkgrid")

sns.pairplot(df_train[num_cols])
plt.suptitle('Числовые фичи', y=1.02)
plt.show()

"""> Относительно четко проглядывается зависимость selling_price от year, km_driven, engine, max_power. Влияние остальных признаков на таргет менее очевидно по визуализации

> Что касается признаков, визуализация говорит о наличии потенциальной связи между engine и max_power, torque и max_power, mileage и engine (в профайлинге был алерт о корреляции между year и km_driven, но я его глазами не особо вижу)
"""

plt.figure(figsize=(12, 10))
sns.set_style("darkgrid")

sns.pairplot(df_test[num_cols])
plt.suptitle('Числовые фичи на тесте', y=1.02)
plt.show()

"""> На первый взгляд почти все распределения совпадают, но по-видимому на тесте больше выбросов, что меняет отображение распределение на пэйплоте

> Плюс заметно иначе выглядит распределения с torque на тесте

### **Задание 9 (0.5 балла)**

И так, вы выдвинули гипотезы о наличии связи. Теперь давайте оценим эту связь в числах.

**Задание:**
- [ ] Получите значения коэффициента корреляции Пирсона для тренировочного набора данных при помощи `pd.corr()`
- [ ] По полученным корреляциям постройте тепловую карту (`heatmap` из бибилотеки seaborn)
"""

corr_matrix = df_train[num_cols].corr(method='pearson')
corr_matrix

plt.figure(figsize=(14, 10))

sns.heatmap(corr_matrix, annot=True)
plt.show()

"""- [ ] Ответьте на вопросы:
 - Какие 2 признака наименее скоррелированы между собой?
 - Между какими наблюдается довольно сильная положительная линейная зависимость?
 - Правильно ли, опираясь на данные, утверждать, что чем меньше год, тем, скорее всего, больше километров проехала машина к дате продажи?
 - Изучите типы корреляций в `pd.corr()`. Какую вы использовали по умолчанию?

Какие 2 признака наименее скоррелированы между собой?

> year и engine (0,0028)

Между какими наблюдается довольно сильная положительная линейная зависимость?

> year, engine, max_power, torque и selling_price (предположения из визуализаций подтвердились)
> engine, torque и max_power
> engine и seats
> seats и torque

Правильно ли, опираясь на данные, утверждать, что чем меньше год, тем, скорее всего, больше километров проехала машина к дате продажи?

> year и km_driven обладают заметной отрицательной корреляцией, так что да

Изучите типы корреляций в `pd.corr()`. Какую вы использовали по умолчанию?

 > По умолчанию там 'pearson', но я её прописывал явно

### **Задание 10 (0.6 балла)**

По умолчанию `pd.corr` возвращает корреляцию Пирсона, говорящую о линейной взаимосвязи. Но зависимости существуют не только линейные! В этой задаче, попробуйте измерить другие способы вычисления корреляций.

- [ ] Реализуйте корреляцию Спирмена/Кендала (на выбор) без использования библиотек (можно пользоваться только `numpy`). Сравните результаты вычисления с библиотечной реализацией
- [ ] Сделайте выводы


Постройте матрицу корреляции [phik](https://pypi.org/project/phik/)
- [ ] Проинтерпретируйте результаты
"""

def spearman_corr(X: pd.DataFrame) -> pd.DataFrame:
  corr_matrix = pd.DataFrame(data=np.zeros((X.shape[1], X.shape[1])),
                         columns=X.columns,
                         index=X.columns)
  X_ranks = X.copy()
  for col in X.columns:
    X_ranks[col] = X[col].rank()

  n = len(X)
  for i in range(len(X_ranks.columns)):
    for j in range(i, len(X_ranks.columns)):
      corr = 1 - 6 * ((X_ranks.iloc[:, i] - X_ranks.iloc[:, j]) ** 2).sum() / (n * (n**2 - 1))
      corr_matrix.iloc[i, j] = corr_matrix.iloc[j, i] = corr

  return corr_matrix

corr_spearman = spearman_corr(df_train[num_cols])
corr_spearman

plt.figure(figsize=(14, 10))

sns.heatmap(corr_spearman, annot=True)
plt.show()

"""> Различия матриц корреляций Пирсона и Спирмена:

- Спирмен показывает более сильную связь year и selling_price (0.71 > 0.43)
- mileage и selling_price по Спирмену почти независимы, хотя по Пирсону есть небольшая отрицательная корреляция - возможно, из-за выбросов
- Спирмен показывает более сильную связь engine и torque (0.82 > 0.65)
- При этом есть пара selling_price - engine, где обе корреляции схожи

> Вывод: в большистве пар корреляции схожи, но в отдельных различаются из-за возможных выбросов или нелинейной связи. Кардинальных противоречий нет.

Построим phik
"""

corr_phik = phik_matrix(df_train[num_cols])

plt.figure(figsize=(12, 10))
mask = np.triu(np.ones_like(corr_phik, dtype=bool))
sns.heatmap(corr_phik,
            mask=mask,
            annot=True,
            fmt='.2f',
            cmap='RdBu_r',
            center=0,
            square=True,
            cbar_kws={'shrink': 0.8})
plt.title('Матрица корреляции phi_k')
plt.tight_layout()
plt.show()

"""Какие выводы можно сделать:

- сильное влияние на цену оказывает max_power, engine, seats
- km_driven и year неожиданно слабо влияет на цену
- по аналогии со сделанными ранее визуализациями видим зависимость engine, max_power, torque

### **Дополнительные визуализации (бонус 0.25 балла)**

Если вам кажется, что мы не попросили вас нарисовать какие-то очень важные зависимости, нарисуйте их и поясните.
Один график: 0.125 балла, при условии, что он обоснован.

>  В визуализациях мы не проверяли наличие выбросов

> График 1: боксплоты для числовых признаков
"""

cols_to_check = [col for col in num_cols if col != 'year'] # в году судя по min_val = 1985 выбросов нет

# в построении красивого боксплота мне помог Claude

fig, axes = plt.subplots(2, 4, figsize=(16, 10))
axes = axes.flatten()

for i, col in enumerate(cols_to_check):
    axes[i].boxplot(df_train[col].dropna(), vert=True)
    axes[i].set_title(f'{col}')
    axes[i].set_ylabel('Значение')

    Q1 = df_train[col].quantile(0.25)
    Q3 = df_train[col].quantile(0.75)
    IQR = Q3 - Q1
    outliers = ((df_train[col] < Q1 - 1.5*IQR) | (df_train[col] > Q3 + 1.5*IQR)).sum()
    axes[i].set_xlabel(f'Потенциальных выбросов: {outliers}')

plt.suptitle('Boxplot для выявления выбросов', y=1.02, fontsize=14)
plt.tight_layout()
plt.show()

"""> График 2: поподробнее посмотрим на распределение таргета

> Построим гистограмму таргета и его логарифма
"""

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

axes[0].hist(df_train['selling_price'], bins=50, edgecolor='black')
axes[0].set_xlabel('Цена продажи')
axes[0].set_ylabel('Частота')
axes[0].set_title('Распределение selling_price')

axes[1].hist(np.log1p(df_train['selling_price']), bins=50, edgecolor='black', color='orange')
axes[1].set_xlabel('log(Цена продажи)')
axes[1].set_ylabel('Частота')
axes[1].set_title('Распределение log(selling_price)')

plt.tight_layout()
plt.show()

"""# **Часть 2 (1.7 балла) | Модель только на вещественных признаках**

В этой части вам предстоит обучить модель только на вещественных признаках. Почему только на них?

Чем больше признаковое пространство — чем сложнее модель. А чем модель проще — тем лучше для скорости работы и интерпретации признаков.

За задания этой части вы можете набрать 1.7 основных и 0.15 бонусных балла;

### **Задание 11 (0.05 балла)**

Разбейте данные на тренировочный и тестовый наборы. Перед разбиением создайте копию датафрейма, который будет хранить только вещественные признаки и используйте его (то есть категориальные столбцы (все, кроме seats) необходимо удалить).

В переменные y_train и y_test запишите значения целевых переменных.
"""

num_cols = [col for col in num_cols if col != 'selling_price']

y_train = df_train['selling_price'].copy()
X_train = df_train[num_cols].copy()

X_train.shape

y_test = df_test['selling_price'].copy()
X_test = df_test[num_cols].copy()

"""### **Задание 12. (0.2 балла)**

Построим нашу первую модель!
- [ ] Обучите классическую линейную регрессию с дефолтными параметрами. Посчтитайте $R^2$ и $MSE$ для трейна и для теста.
- [ ] Сделайте выводы по значениям метрик качества.

**Примечание:**

Здесь и далее $R^2$ и $MSE$ для трейна и для теста выводите везде, где требуется обучать модели, даже если в явном виде этого не просят. Иначе непонятно, как понять, насколько успешны наши эксперименты.
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error as MSE

linreg = LinearRegression()

linreg.fit(X_train, y_train)
y_pred = linreg.predict(X_test)
y_pred_train = linreg.predict(X_train)

r2_train = r2_score(y_train, y_pred_train)
mse_train = MSE(y_train, y_pred_train)

print(f'Метрики на тесте:\n\nR^2 = {r2_train}, MSE = {mse_train}')

r2_test = r2_score(y_test, y_pred)
mse_test = MSE(y_test, y_pred)

print(f'Метрики на тесте:\n\nR^2 = {r2_test}, MSE = {mse_test}')

"""> MSE на тесте в 2 раза хуже, чем на трейне

> R^2 почти такой же

> Можем сделать вывод, что модель не очень хорошо работает на тестовых данных, возможно переобучилась

### **Задание 13 (0.15 балла)**

- [ ] Реализуйте $R^2$ руками. Приведите формулу $R^2$ и объясните каждую компоненту метрики
"""

def r2_custom(y_true: pd.Series, y_pred: pd.Series) -> float:
    mean = y_true.mean()
    y_mean = pd.Series([mean for _ in range(len(y_true))])

    RSS = ((y_true - y_pred) ** 2).sum()
    TSS = ((y_true - y_mean) ** 2).sum()

    return float(1 - RSS / TSS)

r2_custom(y_test, y_pred)

"""> Формула R^2 = 1 - RSS/TSS, где RSS - сумма квадратов остатков, TSS - общая сумма квадратов

![image.png](data:image/png;base64,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)

### **Бонус (0.15 балла)**

- [ ] Реализуйте [$\text{adjusted}-R^2$](https://en.wikipedia.org/wiki/Coefficient_of_determination).
- [ ] Объясните, когда применяется $\text{adjusted}-R^2$?
"""

def r2_adjusted_custom(y_true: pd.Series, y_pred: pd.Series, k: int) -> float:
    n = len(y_true)

    mean = y_true.mean()
    y_mean = pd.Series([mean for _ in range(len(y_true))])

    RSS = ((y_true - y_pred) ** 2).sum()
    TSS = ((y_true - y_mean) ** 2).sum()

    r2_adjusted = 1 - (RSS / (n - k - 1)) / (TSS / (n - 1))

    return float(r2_adjusted)

r2_adjusted_custom(y_test, y_pred, 8)

"""> R2 adjusted штрафует модель за большое количество признаков. Чем больше k, тем меньше значение.

> Если обычный коэффициент детерминации можно улучшать просто добавляя новые признаки (даже если они почти не значимы, R2 улучшится), то с R^2 adj такое не прокатит. Он улучшится, только если добавленный признак действительно вносит вклад в объясняющую способность модели.

### **Задание 14 (0.05 балла)**

Всегда есть место совершенству. Поэтому давайте попробуем улучшить модель. При помощи стандартизации признаков.

- [ ] Стандартизируйте значения в тренировочных и тестовых данных. Стандартизатор **обучайте только на `train`**.
"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)
X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)

X_train_scaled.describe()

linreg.fit(X_train_scaled, y_train)

y_pred = linreg.predict(X_test_scaled)
y_pred_train = linreg.predict(X_train_scaled)

r2_train = r2_score(y_train, y_pred_train)
mse_train = MSE(y_train, y_pred_train)

print(f'Метрики на трейне:\n\nR^2 = {r2_train}, MSE = {mse_train}')

y_train.describe()

r2_test = r2_score(y_test, y_pred)
mse_test = MSE(y_test, y_pred)

print(f'Метрики на тесте:\n\nR^2 = {r2_test}, MSE = {mse_test}')

"""> Результаты не сильно изменились

### **Задание 15 (0.1 балла)**

Хотя стандартизация не помогла сильно прибавить в качестве она открыла возможность интерпретировать важность признаков в модели. Правило интерпретации такое:

Чем больше коэффициент $\beta_i$ по модулю, тем важнее признак.

**Ответьте на вопрос:**

- [ ] Какой признак оказался наиболее информативным в предсказании цены?
"""

linreg.coef_

features = pd.DataFrame({
    'feature': X_train.columns,
    'coefficient': abs(linreg.coef_)
})
features.sort_values('coefficient', ascending=False)

"""> Самым важным признаком с этой точки зрения является max_power

### **Задание 16 (0.25 балла)**

Попробуем улучшить нашу модель с помощью применения регуляризации. Для этого воспльзуемся `Lasso` регрессией.  Кроме того, попробуйте использовать её теоретическое свойство отбора признаков, за счет зануления незначимых коэффициентов.

**Задание:**

- [ ] Обучите Lasso регрессию на тренировочном наборе данных с нормализованными признаками. Оцените её качество
- [ ] Проверьте, занулила ли L1-регуляризация с параметрами по умолчанию какие-нибудь веса? Предположите почему.
"""

from sklearn.linear_model import Lasso

L1 = Lasso()

L1.fit(X_train_scaled, y_train)
y_pred_lasso = L1.predict(X_test_scaled)
y_pred_train_lasso = L1.predict(X_train_scaled)

lasso_r2_train = r2_score(y_train, y_pred_train_lasso)
lasso_mse_train = MSE(y_train, y_pred_train_lasso)

print(f'Метрики на трейне:\n\nR^2 = {lasso_r2_train}, MSE = {lasso_mse_train}')

lasso_r2_test = r2_score(y_test, y_pred_lasso)
lasso_mse_test = MSE(y_test, y_pred_lasso)

print(f'Метрики на тесте:\n\nR^2 = {lasso_r2_test}, MSE = {lasso_mse_test}')

"""> Метрики модели практически не изменились"""

L1.coef_

"""> Веса почти не изменились. Вероятно, из-за того, что L1-регуляризация склонна занулять малозначимые коэффициенты, близкие к нулю.
> В нашей модели похоже все коэффициенты значимы, либо мы взяли неверный alpha

### **Задание 17. Финальный рывок (0.4 балла)**

До этого мы с вами использовали `train` для обучения и `test` для прогнозирования. Но у нас есть ещё одна задача — подобрать оптимальные параметры модели. Для этого используем кросс-валидацию, описанную на семинарах.

Кроме того, выжмем максимум из модификаций регрессии. Построим `ElasticNet`. И сделаем всё по порядку.

**Ваша задача 1:**

- [ ] Перебором по сетке (c 10-ю фолдами) подберите оптимальные параметры для Lasso-регрессии. Вам пригодится класс [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).
- [ ] Ответьте на вопросы:
 - Сколько грид-сёрчу пришлось обучать моделей?
 - Что значит каждый параметр `param_grid`, который вы заполняли для `GridSearch`? Опишите каждый
 - Какой коэффициент регуляризации у лучшей из перебранных моделей? Занулились ли какие-нибудь из весов при такой регуляризации?
"""

from sklearn.linear_model import ElasticNet
from sklearn.model_selection import GridSearchCV

params = {
    'alpha': [0.01, 0.1, 1.0, 10.0, 100.0, 250.0, 300.0, 350.0, 400.0, 500.0],
    'selection': ['cyclic', 'random'],
    'max_iter': [1000, 2000, 5000],
    'tol': [1e-4, 1e-3, 1e-2]
}

lasso_grid = GridSearchCV(
    estimator=Lasso(),
    param_grid=params,
    cv=10,
    scoring='neg_mean_squared_error'
)

lasso_grid.fit(X_train_scaled, y_train)

print("Гиперпараметры:", lasso_grid.best_params_)
print("Лучшее MSE:", -lasso_grid.best_score_)

lasso_linreg = lasso_grid.best_estimator_

y_pred_lasso = lasso_linreg.predict(X_test_scaled)

lasso_r2_test = r2_score(y_test, y_pred_lasso)
lasso_mse_test = MSE(y_test, y_pred_lasso)

print(f'Метрики на тесте:\n\nR^2 = {lasso_r2_test}, MSE = {lasso_mse_test}')

"""> Значение MSE сильно упало по сравнению с тестом без регуляризации

Сколько грид-сёрчу пришлось обучать моделей?
 > 10 alpha х 2 selection x 3 max_iter х 3 tol x 10 фолдов = 1800 моделей

Что значит каждый параметр `param_grid`, который вы заполняли для `GridSearch`? Опишите каждый

 - alpha - коэффициент регуляризации (чем он больше, тем сильнее штраф за величину весов)
 - selection - алгоритм выбора признаков для обновления коэффициентов (интернет подсказал, что в подобных моделях используется Coordinate Descent)
 - max_iter - максимальное число итераций для сходимости алгоритма оптимизации
 - tol - критерий остановки (когда изменение весов между итерациями < tol, алгоритм прекращается)
"""

lasso_grid.best_estimator_.coef_

"""Какой коэффициент регуляризации у лучшей из перебранных моделей? Занулились ли какие-нибудь из весов при такой регуляризации?

 > alpha = 400.0, веса не занулились

**Ваша задача 2:**

- [ ] Перебором по сетке (c 10-ю фолдами) подберите оптимальные параметры для [ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) регрессии.
- [ ] Ответьте на вопрос:
 - Сколько грид-сёрчу пришлось обучать моделей?
 - Какие гиперпараметры соответствуют лучшей (по выбранной метрике качества) из перебранных моделей?
"""

params = {
    'alpha': [100.0, 250.0, 300.0, 350.0, 400.0, 500.0],
    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0],
    'selection': ['cyclic', 'random'],
    'max_iter': [1000, 2000, 5000],
    'tol': [1e-4, 1e-3, 1e-2]
}

elastic_grid = GridSearchCV(
    estimator=ElasticNet(),
    param_grid=params,
    cv=10,
    scoring='neg_mean_squared_error'
)

elastic_grid.fit(X_train_scaled, y_train)

print("Гиперпараметры:", elastic_grid.best_params_)
print("Лучшее MSE:", -elastic_grid.best_score_)

elastic_linreg = elastic_grid.best_estimator_
y_pred_elastic = elastic_linreg.predict(X_test_scaled)

elastic_r2_test = r2_score(y_test, y_pred_elastic)
elastic_mse_test = MSE(y_test, y_pred_elastic)

print(f'Метрики на тесте:\n\nR^2 = {elastic_r2_test}, MSE = {elastic_mse_test}')

"""Сколько грид-сёрчу пришлось обучать моделей?

6 × 6 × 2 × 3 × 3 х 10 = 6480 моделей

Какие гиперпараметры соответствуют лучшей (по выбранной метрике качества) из перебранных моделей?
"""

print("Гиперпараметры:", elastic_grid.best_params_)

"""### **Задание 18 (0.35 балла)**

И так, вы обучили все варианты регуляризаций, доступные в sklearn, но не все, что мы обсудили на занятии! И следующее задание о забытой - $L0$ регуляризации.


**Ваша задача:**>
- [ ] Реализуйте модель с $L0$-регуляризаицей.
- [ ] Обучите модель на данных и проанализируйте результат, экспериментируя с коэффициенитом регуляризации
- [ ] Проанализируйте результаты обучения

**Важно:**

Вопреки тому, что L0 не реализована в стандартных пакетах, концепция данной регуляризации не является мертвой. Она может встречаться в [статьях](https://arxiv.org/abs/1712.01312) и экспериментах.


"""

# В написании данной модели мне помог Claude Sonnet
def l0_regression(X_train, y_train, X_test, y_test, max_features):
    n_features = X_train.shape[1]

    best_mse = float('inf')
    best_features = None
    best_model = None

    X_train = X_train.values
    X_test = X_test.values
    y_train = y_train.values
    y_test = y_test.values

    for features in itertools.combinations(range(n_features), max_features):
        features = list(features)

        model = LinearRegression()
        model.fit(X_train[:, features], y_train)

        y_pred = model.predict(X_test[:, features])
        mse = MSE(y_test, y_pred)

        if mse < best_mse:
            best_mse = mse
            best_features = features
            best_model = model

    return best_model, best_features, best_mse

results = []

for k in range(1, X_train_scaled.shape[1]):
    model, features, mse = l0_regression(
        X_train_scaled, y_train,
        X_test_scaled, y_test,
        max_features=k
    )

    results.append({
        'max_features': k,
        'selected_features': features,
        'test_mse': mse,
        'coefficients': model.coef_
    })

    print(f"\nmax_features = {k}:")
    print(f"  Выбранные признаки: {features}")
    print(f"  Test MSE: {mse:.4f}")

best_idx = np.argmin([r['test_mse'] for r in results])
best_idx

"""> MSE получился не очень, на уровне с обычной регрессией без регуляризации - можно сделать вывод, что незначимых числовых признаков у нас нет

# **Часть 3 (0.5 балла) | Добавляем категориальные фичи**

Попробуем для улучшения модели дать ей больше признаков. Добавим категориальные фичи.

За эту часть можно набрать 0.5 основных балла.
"""

obj_cols = df_train.select_dtypes(include='object').columns
obj_cols = obj_cols.union(['seats'])
obj_cols

X_train_cat = df_train[obj_cols].copy()

X_test_cat = df_test[obj_cols].copy()

"""### **Задание 19 (0.1 балла)**

Проанализируйте столбец `name`. Очевидно, что эта переменная является категориальной, однако категорий в ней много.

- [ ] Предобработайте столбец `name`, чтобы избежать его удаления
"""

X_train_cat['name'].sample(7)

X_train_cat['name'].nunique()

"""> Категорий и правда много, нужно как-то извлечь самую полезную инфу из столбца

> На первом месте всегда стоит марка машины, её можно вынести в отдельный признак
"""

X_train_cat['brand'] = X_train_cat['name'].apply(lambda x: x.split()[0])
X_train_cat['brand'].nunique()

X_train_cat['brand'].value_counts()

"""> Чтобы в будущем не плодить лишние столбцы в OHE, все редкие марки свалим в категорию "Другое"
"""

brand_counts = X_train_cat['brand'].value_counts()
rare_brands = brand_counts[brand_counts < 50].index

X_train_cat['brand'] = X_train_cat['brand'].replace(rare_brands, 'Другое')

X_train_cat['brand'].nunique()

X_train_cat = X_train_cat.drop(columns='name', axis=1)

# assert X_train_cat.shape == (5840, 11)

"""> Полдня просидел с перекодированием name, но так и не понял, как сгенерить 6 столбцов для выполнения ассерта

> Из адекватных способов придумал только взять название марки

> Мб надо было найти какой-то паттерн в названии, но я не смог :(
"""

X_train_cat.describe(include='object')

obj_cols = df_train.select_dtypes(include='object').columns
obj_cols = obj_cols.union(['seats'])
obj_cols

"""Не забудем про X_test_cat"""

X_test_cat['brand'] = X_test_cat['name'].apply(lambda x: x.split()[0])
brand_counts = X_test_cat['brand'].value_counts()
rare_brands = brand_counts[brand_counts < 20].index

X_test_cat['brand'] = X_test_cat['brand'].replace(rare_brands, 'Другое')

X_test_cat = X_test_cat.drop(columns='name', axis=1)

"""### **Задание 20 (0.1 балла)**

- [ ] Закодируйте категориалльные фичи и ``seats`` методом OneHot-кодирования.
"""

X_train_cat.info()

from sklearn.preprocessing import OneHotEncoder # или можно использовать get_dummies из библиотеки pandas

ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
X_train_cat_encoded = ohe.fit_transform(X_train_cat)

feature_names = ohe.get_feature_names_out()

X_train_cat_encoded = pd.DataFrame(
    X_train_cat_encoded,
    columns=feature_names,
    index=X_train_cat.index
)

X_train_cat_encoded.head()

X_test_cat_encoded = pd.DataFrame(
    ohe.transform(X_test_cat),
    columns=feature_names,
    index=X_test_cat.index
)

X_test_cat_encoded.columns

X_train_cat_encoded.shape

X_test_cat_encoded.shape

"""### **Задание 21 (0.2 балла)**

OHE — базовый алгоритм преобразования категориальных признаков, но и с ним нужно быть аккуратными.

**Ответьте на вопросы:**


* Как корректно работать с OHE преобразованием?
* Почему мы удаляем один столбец?
* Пусть из $n$ признаков мы получили $n-1$ столбец, из которых $k < n -1$ оказались не важными по весам модели. Корректно ли их удалить?

### Ответы

Как корректно работать с OHE преобразованием?

- обучать только на трейне, а на тесте лишь применять
- если категорий очень много, расплодим признаки и может быть плохо
- на тесте могут попаться категории, которых не было на трейне - при инициализации энкодера handle_unknown='ignore'

Почему мы удаляем один столбец?

> Чтобы не попасть в дамми ловушку и не создать мультиколлинеарность (когда столбцы в сумме дают единичный столбец)

Пусть из  n  признаков мы получили  n−1  столбец, из которых  k<n−1  оказались не важными по весам модели. Корректно ли их удалить?

> Нет, тк эти n-1 столбцов также кодируют и n-ный столбец, который пропущен по причине выше. Соответственно удаление n-1 незначимых столбцов лишает нас информации о пропущенном n-ном столбце и в совокупности группа этих столбцов может быть значима.

> Перед удалением стоит провести тест (например тест Фишера) сразу для всей группы столбцов и уже тогда судить об их значимости

### **Задание 22 (0.1 балла)**
Повторим то, что делали на прошлом шаге для моделей на вещественных признаках, однако теперь с моделью `Ridge`.


**Ваша задача:**
- [ ] Переберите параметр регуляризации `alpha` для гребневой (ridge) регрессии с помощью класса `GridSearchCV` В качестве параметров при объявлении GridSearchCV кроме модели укажите метрику качества $R^2$. Кроссвалидируйтесь по 10-ти фолдам.
- [ ] Ответье на вопрос: Удалось ли улучшить качество прогнозов?

> Объединим все признаки в один датафрейм
"""

X_train_combined = pd.concat([X_train_scaled, X_train_cat_encoded], axis=1)
X_train_combined = X_train_combined.drop(columns='seats')

print(f"Размер итогового датафрейма: {X_train_combined.shape}")

X_test_combined = pd.concat([X_test_scaled, X_test_cat_encoded], axis=1)
X_test_combined = X_test_combined.drop(columns='seats')

print(f"Размер итогового датафрейма: {X_test_combined.shape}")

from sklearn.linear_model import Ridge
from sklearn.model_selection import GridSearchCV

params = {
    'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 250.0, 500.0, 1000.0]
}

ridge_grid = GridSearchCV(
    estimator=Ridge(),
    param_grid=params,
    cv=10,
    scoring='r2'
)

ridge_grid.fit(X_train_combined, y_train)

print("Лучшие гиперпараметры:", ridge_grid.best_params_)
print("Лучший R² на кросс-валидации:", ridge_grid.best_score_)

"""Посмотрим на метрики на тесте"""

ridge_linreg = ridge_grid.best_estimator_

y_pred_ridge = ridge_linreg.predict(X_test_combined)

ridge_r2_test = r2_score(y_test, y_pred_ridge)
ridge_mse_test = MSE(y_test, y_pred_ridge)


print(f'Метрики на тесте:\n\nR^2 = {ridge_r2_test}, MSE = {ridge_mse_test}')

"""> Чекнем результаты наших моделей"""

results_df = pd.DataFrame({
    'Model': ['Обычная регрессия', 'Lasso', 'ElasticNet', 'Ridge'],
    'R2_test': [r2_test, lasso_r2_test, elastic_r2_test, ridge_r2_test],
    'MSE_test': [mse_test, lasso_mse_test, elastic_mse_test, ridge_mse_test]
})
results_df

"""> Ridge с категориальными признаками уверенно побеждает!

> Проверим остальные модели с категориальными фичами
"""

def grid_search(model, params, scoring, name):
  grid = GridSearchCV(
      estimator=model,
      param_grid=params,
      cv=10,
      scoring=scoring
  )

  grid.fit(X_train_combined, y_train)

  print(f'\nРезультаты для {name}\n')

  print("Лучшие гиперпараметры:", grid.best_params_)
  print("Лучшая метрика на кросс-валидации:", grid.best_score_)

  return grid.best_estimator_

linreg_combined = grid_search(model=LinearRegression(),
                              params={},
                              scoring='r2',
                              name='Линейная регрессия')

# Ridge
ridge_combined = grid_search(model=Ridge(),
                            params={'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},
                            scoring='r2',
                            name='Ridge')

# Lasso
lasso_combined = grid_search(model=Lasso(max_iter=10000),
                            params={'alpha': [1000, 1500, 1750, 1790, 1800, 1850, 2000]},
                            scoring='r2',
                            name='Lasso')

# ElasticNet
elastic_combined = grid_search(model=ElasticNet(max_iter=10000),
                              params={
                                  'alpha': [0.01, 0.1, 1.0],
                                  'l1_ratio': [0.5, 0.6, 0.7, 0.9]
                              },
                              scoring='r2',
                              name='ElasticNEt')

results = []

# Линейная регрессия
y_pred_linreg_combined = linreg_combined.predict(X_test_combined)
mse_linreg_combined = MSE(y_test, y_pred_linreg_combined)
r2_linreg_combined = r2_score(y_test, y_pred_linreg_combined)
results.append({
    'Модель': 'Линейная регрессия',
    'R²': r2_linreg_combined,
    'MSE': mse_linreg_combined
})

# Ridge
y_pred_ridge_combined = ridge_combined.predict(X_test_combined)
mse_ridge_combined = MSE(y_test, y_pred_ridge_combined)
r2_ridge_combined = r2_score(y_test, y_pred_ridge_combined)
results.append({
    'Модель': 'Ridge',
    'R²': r2_ridge_combined,
    'MSE': mse_ridge_combined
})

# Lasso
y_pred_lasso_combined = lasso_combined.predict(X_test_combined)
mse_lasso_combined = MSE(y_test, y_pred_lasso_combined)
r2_lasso_combined = r2_score(y_test, y_pred_lasso_combined)
results.append({
    'Модель': 'Lasso',
    'R²': r2_lasso_combined,
    'MSE': mse_lasso_combined
})

# ElasticNet
y_pred_elastic_combined = elastic_combined.predict(X_test_combined)
mse_elastic_combined = MSE(y_test, y_pred_elastic_combined)
r2_elastic_combined = r2_score(y_test, y_pred_elastic_combined)
results.append({
    'Модель': 'ElasticNet',
    'R²': r2_elastic_combined,
    'MSE': mse_elastic_combined
})

results_df_combined = pd.DataFrame(results)
results_df_combined = results_df_combined.sort_values('MSE')
results_df_combined

"""# **Часть 4 - бонусная (1 балл) | Feature Engineering**

В этой части домашнего задания вам предлагается проявить свою креативность для улучшения прогноза модели. Любые другие модели, кроме различных форм линейной (или полиномиальной) регресси, использовать запрещается. А значит, придется работать с признаками

**Что можно попробовать сделать?** (каждый пункт по 0.4 балла, но не больше 1-х балла в сумме)

1.   *Сгенерировать новые признаки на основе уже существующих:*
    * посчитать произведения // частные признаков (кажется, что посчитать число "лошадей" на литр объема может быть полезно);
    * имеет смысл обратить внимание на визуализации в части с EDA (к примеру, зависимость цены от года выглядит квадратичной, а не линейной; значит, квадрат года нам, скорее всего, принесет больше пользы)

2.   *Добыть новые признаки:*
    * имеем название автомобиля, которое никак не используем (можно спарсить инфу о классе автомобиля или каких-то специфических опциях)
    * можно добавить пороговые признаки вроде "владелец третий или больше" и объединить признаки в некоторые осмысленные правила, например "первый или второй владелец и продавец официальный дилер" (подбирать пороги удобно по диаграммам рассеяния)

3.   *Поработать с уже имеющимися:*
    * далеко не факт, что заполнить пропуск медианой было лучшей идеей (как минимум, можно добавить dummy-столбец для модели, сигнализирующий, что раньше на месте медианы был пропуск -- там где он был, конечно); попробуйте другие способы филлинга;
    * мы не анализировали, есть ли в данных выбросы => никак выбросы не обрабатывали; наиболее простым и, тем не менее, довольно полезным вариантом нахождения выбросов могут послужить boxplot'ы для каждого столбца; что делать с выбросами думайте сами :) -- вариантов довольно много
    * мы толком не смотрели на таргет сам по себе; в нем тоже могут быть неожиданности -- стоит хотя бы проверить
    * можно заметить, что некоторые признаки распределены совсем не нормально; возможно их стоит отлогарифмировать

И так далее...

Feel Free to Try!

### Пункт 1
"""

X_train_advanced = X_train_combined.copy()
X_test_advanced = X_test_combined.copy()

"""> Попытаемся добавить относительные численные признаки: Мощность на литр объема двигателя, Крутящий момент на литр объема, Удельная мощность - используем пробег как косвенный показатель износа"""

X_train_advanced['power_per_liter'] = X_train_advanced['max_power'] / X_train_advanced['engine']
X_train_advanced['torque_per_liter'] = X_train_advanced['torque'] / X_train_advanced['engine']
X_train_advanced['specific_power'] = X_train_advanced['max_power'] / (X_train_advanced['km_driven'] + 1)

X_test_advanced['power_per_liter'] = X_test_advanced['max_power'] / X_test_advanced['engine']
X_test_advanced['torque_per_liter'] = X_test_advanced['torque'] / X_test_advanced['engine']
X_test_advanced['specific_power'] = X_test_advanced['max_power'] / (X_test_advanced['km_driven'] + 1)

"""> Посмотрим, есть ли нелинейные зависимости между таргетом и числовыми признаками"""

num_cols.remove('seats')
num_cols

fig, axes = plt.subplots(2, 4, figsize=(20, 10))

for i, col in enumerate(num_cols):
    row = i // 4
    col_idx = i % 4

    if i < 8:
        axes[row, col_idx].scatter(df_train[col], y_train, alpha=0.5)
        axes[row, col_idx].set_title(f'{col} x selling_price')
        axes[row, col_idx].set_xlabel(col)
        axes[row, col_idx].set_ylabel('selling_price')

plt.tight_layout()
plt.show()

"""> Зависимость selling_price от year действительно выглядит квадратичной, добавим квадрат года в признаки"""

X_train_advanced['year_squared'] = df_train['year'] ** 2
X_test_advanced['year_squared'] = df_test['year'] ** 2

"""Отскейлим наши новые признаки"""

new_cols = ['year_squared', 'power_per_liter', 'torque_per_liter', 'specific_power']
new_scaler = StandardScaler()

X_train_advanced[new_cols] = new_scaler.fit_transform(X_train_advanced[new_cols])
X_test_advanced[new_cols] = new_scaler.transform(X_test_advanced[new_cols])

X_train_advanced[new_cols].describe()

"""### Пункт 2"""

X_train_advanced.info()

"""> Добавим признак "Третий владелец и более"
"""

X_train_advanced['owner_third_or_more'] = (
    X_train_advanced['owner_Third Owner'] +
    X_train_advanced['owner_Fourth & Above Owner']
).astype(float)

X_test_advanced['owner_third_or_more'] = (
    X_test_advanced['owner_Third Owner'] +
    X_test_advanced['owner_Fourth & Above Owner']
).astype(float)

"""> Добавим признак "Первый владелец + Официальный дилер"
"""

X_train_advanced['premium_seller_first_owner'] = (
    (X_train_advanced['owner_First Owner'] == 1) &
    (X_train_advanced['seller_type_Trustmark Dealer'] == 1)
).astype(float)

X_test_advanced['premium_seller_first_owner'] = (
    (X_test_advanced['owner_First Owner'] == 1) &
    (X_test_advanced['seller_type_Trustmark Dealer'] == 1)
).astype(float)

"""Добавим признак "Высокий риск" = много владельцев + частный продавец"""

X_train_advanced['risk_combination'] = (
    (X_train_advanced['owner_third_or_more'] == 1) &
    (X_train_advanced['seller_type_Individual'] == 1)
).astype(float)

X_test_advanced['risk_combination'] = (
    (X_test_advanced['owner_third_or_more'] == 1) &
    (X_test_advanced['seller_type_Individual'] == 1)
).astype(float)

"""Добавим признак "Первый владелец + низкий пробег (менее 50000)"
"""

X_train_advanced['low_mileage_first_owner'] = (
    (X_train_advanced['owner_First Owner'] == 1) &
    (X_train_advanced['km_driven'] < 50000)
).astype(float)

X_test_advanced['low_mileage_first_owner'] = (
    (X_test_advanced['owner_First Owner'] == 1) &
    (X_test_advanced['km_driven'] < 50000)
).astype(float)

"""> Как выжать какую-то другую адекватную информацию из признака name я не придумал ^(

### Пункт 3

> Подумаем, что можно сделать с выбросами. Взглянем еще раз на боксплоты:
"""

num_cols.append(new_cols)

fig, axes = plt.subplots(2, 4, figsize=(16, 10))
axes = axes.flatten()

for i, col in enumerate(num_cols):
    axes[i].boxplot(X_train_advanced[col].dropna(), vert=True)
    axes[i].set_title(f'{col}')
    axes[i].set_ylabel('Значение')

    Q1 = X_train_advanced[col].quantile(0.25)
    Q3 = X_train_advanced[col].quantile(0.75)
    IQR = Q3 - Q1
    outliers = ((X_train_advanced[col] < Q1 - 1.5*IQR) | (X_train_advanced[col] > Q3 + 1.5*IQR)).sum()
    axes[i].set_xlabel(f'Потенциальных выбросов: {outliers}')

plt.suptitle('Boxplot для выявления выбросов', y=1.02, fontsize=14)
plt.tight_layout()
plt.show()

"""> Много выбросов наблюдается в следующих колонках:"""

cols_with_outliers = ['engine', 'power_per_liter', 'specific_power', 'torque_per_liter']

"""> Тут я долго игрался с тем, как обработать потенциальные выбросы - я пробовал логарифмировать, Робаст скейлить, обрезать хвосты - но модели от этого становились только хуже, либо вообще не сходились

> Так как дедлайн поджимал, решил оставить это в незавершенном виде - но времени в этот пункт убил много...
"""

# from scipy.stats.mstats import winsorize

# limits = (0.05, 0.05)

# for col in cols_with_outliers:
#     X_train_advanced[col] = winsorize(X_train_advanced[col], limits=limits)

# for col in cols_with_outliers:
#     X_test_advanced[col] = winsorize(X_test_advanced[col], limits=limits)

X_train_advanced[cols_with_outliers].describe()

"""> Взглянем на итоговый датасет"""

new = num_cols.pop(-1)
num_cols.extend(new)
num_cols

X_train_advanced.describe(include='float64')

X_test_advanced.describe()

"""> Обучим модельки на датасете с новым признаками и замерим качество!"""

def grid_search(model, params, scoring, name):
  grid = GridSearchCV(
      estimator=model,
      param_grid=params,
      cv=10,
      scoring=scoring
  )

  grid.fit(X_train_advanced, y_train)

  print(f'\nРезультаты для {name}\n')

  print("Лучшие гиперпараметры:", grid.best_params_)
  print("Лучшая метрика на кросс-валидации:", grid.best_score_)

  return grid.best_estimator_

linreg_advanced = grid_search(model=LinearRegression(),
                              params={},
                              scoring='r2',
                              name='Линейная регрессия')

# Ridge
ridge_advanced = grid_search(model=Ridge(),
                            params={'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},
                            scoring='r2',
                            name='Ridge')

# Lasso
lasso_advanced = grid_search(model=Lasso(max_iter=10000),
                            params={'alpha': [1000, 1500, 1750, 1790, 1800, 1850, 2000]},
                            scoring='r2',
                            name='Lasso')

# ElasticNet
elastic_advanced = grid_search(model=ElasticNet(max_iter=10000),
                              params={
                                  'alpha': [0.01, 0.1, 1.0],
                                  'l1_ratio': [0.5, 0.6, 0.7, 0.9]
                              },
                              scoring='r2',
                              name='ElasticNEt')

results = []

# Линейная регрессия
y_pred_linreg_advanced = linreg_advanced.predict(X_test_advanced)
mse_linreg_advanced = MSE(y_test, y_pred_linreg_advanced)
r2_linreg_advanced = r2_score(y_test, y_pred_linreg_advanced)
results.append({
    'Модель': 'Линейная регрессия',
    'R²': r2_linreg_advanced,
    'MSE': mse_linreg_advanced
})

# Ridge
y_pred_ridge_advanced = ridge_advanced.predict(X_test_advanced)
mse_ridge_advanced = MSE(y_test, y_pred_ridge_advanced)
r2_ridge_advanced = r2_score(y_test, y_pred_ridge_advanced)
results.append({
    'Модель': 'Ridge',
    'R²': r2_ridge_advanced,
    'MSE': mse_ridge_advanced
})

# Lasso
y_pred_lasso_advanced = lasso_advanced.predict(X_test_advanced)
mse_lasso_advanced = MSE(y_test, y_pred_lasso_advanced)
r2_lasso_advanced = r2_score(y_test, y_pred_lasso_advanced)
results.append({
    'Модель': 'Lasso',
    'R²': r2_lasso_advanced,
    'MSE': mse_lasso_advanced
})

# ElasticNet
y_pred_elastic_advanced = elastic_advanced.predict(X_test_advanced)
mse_elastic_advanced = MSE(y_test, y_pred_elastic_advanced)
r2_elastic_advanced = r2_score(y_test, y_pred_elastic_advanced)
results.append({
    'Модель': 'ElasticNet',
    'R²': r2_elastic_advanced,
    'MSE': mse_elastic_advanced
})

results_df_advanced = pd.DataFrame(results)
results_df_advanced = results_df_advanced.sort_values('MSE')
results_df_advanced

"""> Лучше всего себя показывает по обеим метрикам Lasso!"""

lasso_advanced.intercept_, lasso_advanced.coef_

"""> Заметим, что много весов занулилось :)

# **Часть 4. | Бизнесовая (0.5 балла)**

### **Задание 23 (0.25 балла)**

В мире бизнеса очень важно давать оценку качества модели понятную бизнесу, поэтому иногда заказчики приходят с кастомными метриками. Попробуем сделать такую для нашей задачи.

**Описание метрики:**

Среди всех предсказанных цен на авто нужно посчитать долю прогнозов, отличающихся от реальных цен на эти авто не более чем на 10% (в одну или другую сторону)

**Ваша задача:**

- [ ] Реализуйте метрику `business_metric`
- [ ] Посчитайте метрику для всех обученных моделей и определеите, какаю лучше всего решает задачу бизнеса
"""

def business_metric(y_true, y_pred):
    absolute_percentage_error = np.abs((y_true - y_pred) / y_true)

    within_tolerance = absolute_percentage_error <= 0.1
    proportion = np.mean(within_tolerance)

    return proportion

results = []

# Линейная регрессия
y_pred_linreg_advanced = linreg_advanced.predict(X_test_advanced)
mse_linreg_advanced = MSE(y_test, y_pred_linreg_advanced)
r2_linreg_advanced = r2_score(y_test, y_pred_linreg_advanced)
business_metric_linreg = business_metric(y_test, y_pred_linreg_advanced)
results.append({
    'Модель': 'Линейная регрессия',
    'R²': r2_linreg_advanced,
    'MSE': mse_linreg_advanced,
    'Business Metric': business_metric_linreg
})

# Ridge
y_pred_ridge_advanced = ridge_advanced.predict(X_test_advanced)
mse_ridge_advanced = MSE(y_test, y_pred_ridge_advanced)
r2_ridge_advanced = r2_score(y_test, y_pred_ridge_advanced)
business_metric_ridge = business_metric(y_test, y_pred_ridge_advanced)
results.append({
    'Модель': 'Ridge',
    'R²': r2_ridge_advanced,
    'MSE': mse_ridge_advanced,
    'Business Metric': business_metric_ridge
})

# Lasso
y_pred_lasso_advanced = lasso_advanced.predict(X_test_advanced)
mse_lasso_advanced = MSE(y_test, y_pred_lasso_advanced)
r2_lasso_advanced = r2_score(y_test, y_pred_lasso_advanced)
business_metric_lasso = business_metric(y_test, y_pred_lasso_advanced)
results.append({
    'Модель': 'Lasso',
    'R²': r2_lasso_advanced,
    'MSE': mse_lasso_advanced,
    'Business Metric': business_metric_lasso
})

# ElasticNet
y_pred_elastic_advanced = elastic_advanced.predict(X_test_advanced)
mse_elastic_advanced = MSE(y_test, y_pred_elastic_advanced)
r2_elastic_advanced = r2_score(y_test, y_pred_elastic_advanced)
business_metric_elastic = business_metric(y_test, y_pred_elastic_advanced)
results.append({
    'Модель': 'ElasticNet',
    'R²': r2_elastic_advanced,
    'MSE': mse_elastic_advanced,
    'Business Metric': business_metric_elastic
})

results_df_advanced = pd.DataFrame(results)
results_df_advanced = results_df_advanced.sort_values('Business Metric', ascending=False)
results_df_advanced

"""### **Задание 24 (0.25 балла)**

Но у бизнеса не всегда есть идеи и иногда задача на выбор метрики делегируется вам.

**Задание:**

- [ ] Придумайте и реализуйте другую кастомную метрику с учетом того, что модель не должна сильно ошибаться в прогнозе, но недопрогноз для модели, согласно мнению бизнеса, хуже, чем перепрогноз.
- [ ] Посчитайте метрику для всех обученных моделей и определеите, какаю лучше всего решает задачу бизнеса

> В зависимости от того, продаем мы или покупаем машины, превышение или недобор цены в прогнозе могут иметь для нас разную значимость

> Сделаем метрику с двумя параметрами alpha и beta, которые определяют коридор между перепрогнозом и недопрогнозом
"""

def your_business_metrics(y_true, y_pred, alpha=0.4, beta=0.1):
    percentage_error = (y_pred - y_true) / y_true

    overprediction = alpha
    underprediction = beta

    acceptable = (
        (percentage_error <= overprediction) &
        (percentage_error >= -underprediction)
    )

    proportion = np.mean(acceptable)
    return proportion

"""> Допустим, для нас недопрогноз в разы страшнее перепрогноза - alpha = 0.4, beta = 0.1 (перепрогноз до 30% - ок, но недопрогноз только до 10% - ок)"""

results_custom = []

# Линейная регрессия
y_pred_linreg_advanced = linreg_advanced.predict(X_test_advanced)
business_metric_linreg = your_business_metrics(y_test, y_pred_linreg_advanced)
results_custom.append({
    'Модель': 'Линейная регрессия',
    'Custom business Metric': business_metric_linreg
})

# Ridge
y_pred_ridge_advanced = ridge_advanced.predict(X_test_advanced)
business_metric_ridge = your_business_metrics(y_test, y_pred_ridge_advanced)
results_custom.append({
    'Модель': 'Ridge',
    'Custom business Metric': business_metric_ridge
})

# Lasso
y_pred_lasso_advanced = lasso_advanced.predict(X_test_advanced)
business_metric_lasso = your_business_metrics(y_test, y_pred_lasso_advanced)
results_custom.append({
    'Модель': 'Lasso',
    'Custom business Metric': business_metric_lasso
})

# ElasticNet
y_pred_elastic_advanced = elastic_advanced.predict(X_test_advanced)
business_metric_elastic = your_business_metrics(y_test, y_pred_elastic_advanced)
results_custom.append({
    'Модель': 'ElasticNet',
    'Custom business Metric': business_metric_elastic
})

results_custom_df = pd.DataFrame(results_custom)
results_custom_df = results_custom_df.sort_values('Custom business Metric', ascending=False)
results_custom_df

"""> Lasso тут работает лучше всех остальных

> Значения метрики сомнительное, но окэээй. Имеем что имеем...

# **Часть 6 (1 балл) | Оформление результатов**

### **Задание 25**

**Результаты вашей работы** необходимо разместить в своем Гитхабе. Далее в этот же репозиторий вы прикрепите вторую часть. Под результатами первой части понимаем следующее:
* ``.ipynb``-ноутбук со всеми проведёнными вами экспериментами (output'ы ячеек, разумеется, сохранить)
* ``.pickle``-файл с сохранёнными весами модели, коэффициентами скейлинга и прочими числовыми значениями, которые могут понадобиться для инференса
* ``.md``-файл с выводами про проделанной вами работе:
    * что было сделано
    * с какими результатами
    * что дало наибольший буст в качестве
    * что сделать не вышло и почему (это нормально, даже хорошо😀)

**За что могут быть сняты баллы в этом пункте:**
* за отсутствие ``.pickle``-файла с весами использованной модели
* за недостаточную аналитику в ``.md``-файле
* за оформление и логику кода (в определённом смысле это тоже элемент оформления решения)
"""

import pickle
import datetime

artifacts = {
        'timestamp': datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'best_model': lasso_advanced,
        'scaler': scaler,
        'new_scaler': new_scaler,
        'ohe_encoder': ohe,
        'feature_names': X_train_advanced.columns.tolist(),
        'model_metrics': {
            'best_model_name': 'Lasso',
            'test_r2': r2_lasso_advanced,
            'test_mse': mse_lasso_advanced,
            'business_metric': business_metric_lasso
        }
    }

with open('model.pkl', 'wb') as f:
  pickle.dump(artifacts, f)

"""https://github.com/notglebatall/ML_homework/"""