# Что было сделано

### 1. EDA
- Выявлены пропуски в столбцах `mileage`, `engine`, `max_power`, `torque`, `seats`
- Обнаружено и удалено 493 дубликата
- Построен отчет с помощью `ydata-profiling`
- Проанализированы статистики числовых и категориальных признаков на трейне и тесте

### 2. Предобработка данных
- Преобразованы текстовые признаки в числовые:
  - `mileage`, `engine`, `max_power` - удалены единицы измерения
  - `torque` - разделен на два признака: `torque` и `max_torque_rpm`
- Заполнены пропуски медианными значениями (медиана выбрана из-за наличия выбросов)
- Приведены типы данных к корректным (`engine` и `seats` → int)
- Проведена стандартизация числовых признаков

### 3. Визуализация
- Построены pairplot'ы для числовых признаков
- Рассчитаны корреляции Пирсона и Спирмена
- Выявлены сильные корреляции между:
  - `year`, `engine`, `max_power`, `torque` и `selling_price`
  - `engine` и `max_power`
  - `engine` и `seats`
- Построены boxplot'ы для выявления выбросов

### 4. Обработка категориальных признаков
- Из столбца `name` извлечена марка автомобиля (`brand`)
- Редкие марки (< 50 упоминаний) объединены в категорию "Другое"
- Применено OHE для всех категориальных признаков

### 5. Обучение базовых моделей

#### Модели только на числовых признаках:
- **Линейная регрессия**: R² = 0.599, MSE = 2.302e+11
- **Lasso** (с подбором alpha через GridSearchCV): R² = 0.598, MSE = 	2.305e+11
- **ElasticNet** (с подбором гиперпараметров): R² = 0.598, MSE = 2.305e+11
- **L0-регрессия** (реализована вручную): результаты на уровне обычной регрессии

#### Модели с категориальными признаками:
- **Ridge** (с подбором alpha): R² = 0.693, MSE = 1.763e+11

### 6. Feature Engineering (бонусная часть)

Созданы новые признаки:
- **Относительные признаки**:
  - `power_per_liter` - мощность на литр объема двигателя
  - `torque_per_liter` - крутящий момент на литр объема
  - `specific_power` - удельная мощность с учетом пробега
  - `year_squared` - квадрат года (для учета нелинейной зависимости)

- **Комбинированные признаки**:
  - `owner_third_or_more` - третий владелец и более
  - `premium_seller_first_owner` - первый владелец + официальный дилер
  - `risk_combination` - много владельцев + частный продавец
  - `low_mileage_first_owner` - первый владелец + низкий пробег

### 7. Финальные результаты с Feature Engineering

<img width="407" height="177" alt="image" src="https://github.com/user-attachments/assets/36701f0b-d10d-41b2-a953-28552a899d08" />


### 8. Бизнес-метрики
- Реализована метрика "доля прогнозов с ошибкой ≤ 10%"
- Создана кастомная метрика с асимметричными порогами (учитывает, что недопрогноз хуже перепрогноза)
- Лучшие результаты показала модель **Lasso**

# Результаты

### Лучшая модель на R^2 и MSE: Ridge на категориальных данных без feature engineering
- **R² на тесте**: 0.693
- **MSE на тесте**: 1.763e+11

### Улучшение относительно базовой модели:
- Улучшение MSE: с 2.302e+11 до 1.763e+11
- Улучшение R²: с 0.599 до 0.693

### Лучшая модель на бизнес-метриках: Lasso на категориальных данных + feature engineering
- **Business metric**:

<img width="533" height="189" alt="image" src="https://github.com/user-attachments/assets/0492da9e-978b-4b25-85b5-1b258facf7c7" />

- **Custom business  metric**:

<img width="396" height="187" alt="image" src="https://github.com/user-attachments/assets/10d780dc-6f2d-4592-8fc9-8ec65929dd32" />


# Что дало наибольший буст в качестве

### 1. Добавление категориальных признаков (+11% R²)
Без категориальных:

<img width="382" height="139" alt="image" src="https://github.com/user-attachments/assets/e5398fa1-55e4-460d-9c2f-3d3edad6e4ed" />

С категориальными:

<img width="384" height="171" alt="image" src="https://github.com/user-attachments/assets/c32b33ee-606a-4b76-8674-d8005e7a4caa" />


### 2. Регуляризация (Lasso) 
- L1-регуляризация помогла отобрать наиболее значимые признаки
- Занулила несколько весов, что упростило модель
- Дала небольшое, но стабильное улучшение качества

### 3. Подбор гиперпараметров через GridSearchCV
- Систематический перебор параметров позволил найти оптимальные значения
- Особенно важно для коэффициента регуляризации alpha

# Что сделать не вышло и почему

### 1. Обработка выбросов
**Что пробовал:**
- Винсоризация (обрезка хвостов распределения)
- Логарифмирование признаков с выбросами
- RobustScaler вместо StandardScaler

**Почему не сработало:**
- Модели становились хуже или не сходились
- Выбросы, вероятно, несут важную информацию (дорогие/редкие автомобили)
- Возможно, нужны более сложные методы (например, изоляция выбросов в отдельные сегменты)

### 2. Более глубокая работа с признаком `name`
**Что хотел сделать:**
- Извлечь модель автомобиля, класс, специальные опции
- Использовать внешние источники данных о характеристиках моделей

**Почему не получилось:**
- Слишком много уникальных значений (>2000)
- Нет четкого паттерна в названиях
- Требуется парсинг внешних источников или ручная разметка
- Ограничение по времени

### 3. Полиномиальные признаки
**Что хотел попробовать:**
- PolynomialFeatures для создания взаимодействий признаков
- Степени 2-3 для числовых признаков

**Почему не сделал:**
- Не успел к дедлайну :(

### 4. Работа с таргетом
**Что заметил:**
- Распределение `selling_price` имеет длинный правый хвост
- Логарифмирование таргета могло бы помочь

**Почему не реализовал:**
- Не успел к дедлайну :(

### 5. Feature Engineering
Создание новых признаков ухудшило результаты моделей:

<img width="395" height="178" alt="image" src="https://github.com/user-attachments/assets/c5cd98aa-54b5-48a5-bd74-67c2614cf3bf" />

К сожалению, улучшить качество таким образом я не смог :(

# Выводы

1. **Категориальные признаки критически важны** для предсказания цены автомобиля - они дали основной прирост качества

2. **Feature Engineering не сработал**, но скорее всего это из-за моей плохой реализации

3. **Регуляризация (особенно Lasso) полезна** при большом количестве признаков для отбора наиболее значимых

4. **Дедлайны душат**: многие идеи остались нереализованными из-за дедлайна

6. **Важность EDA**: визуализации помогли выявить нелинейные зависимости (например, квадратичная зависимость от года)

7. **GridSearchCV - маст хэв** для подбора гиперпараметров, но требует вычислительных ресурсов

## Что можно улучшить в будущем

- Более тщательная работа с выбросами (сегментация данных)
- Глубокий парсинг признака `name` с использованием внешних источников
- Эксперименты с логарифмированием таргета
- Полиномиальные признаки
- Ансамблирование нескольких моделей
- Более сложные методы заполнения пропусков

## Оценка разработанного streamlit-приложения

- Приложение получилось удобное и юзер-френдли (постарался везде добавить обработку ошибок)
- Хорошо получилось визуализировать первичное EDA, которое не требовало преобразований признаков - для остального необходимо тратить гораздо больше времени и сил
- Основное ограничение - это статичность: можно отобразить только то, что заготовлено заранее в коде
- В последующих итерациях можно расширить область EDA, доступную юзеру: добавить не только первичный анализ, но и последующие стадии с заполнением пропусков и перекодировкой категориальных признаков + необходимо улучшить качество самой модели
- Улучшения по организации кода: можно переорганизовать код, объединяя цепи преобразований в пайплайны - но к дедлайну сделать этого я не успел
